@incollection{ACM:83,
  author = {Association for Computing Machinery},
  year = "1983",
  booktitle = {Computing Reviews},
  volume = "24",
  number = "11",
  pages = "503--512"
}

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
   publisher = {American Psychological Association},
   address = {Washington, DC}
}

@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume={3},
  number={Feb},
  pages={1137--1155},
  year={2003}
}

@article{bullinaria2007extracting,
  title={Extracting semantic representations from word co-occurrence statistics: A computational study},
  author={Bullinaria, John A and Levy, Joseph P},
  journal={Behavior research methods},
  volume={39},
  number={3},
  pages={510--526},
  year={2007},
  publisher={Springer}
}

@article{Chandra:81,
  author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
  year = "1981",
  title = {Alternation},
  journal = {Journal of the Association for Computing Machinery},
  volume = "28",
  number = "1",
  pages = "114--133"
}

@article{cho2014learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year="2014"
}

@article{church1990word,
  title={Word association norms, mutual information, and lexicography},
  author={Church, Kenneth Ward and Hanks, Patrick},
  journal={Computational linguistics},
  volume={16},
  number={1},
  pages={22--29},
  year={1990},
  publisher={MIT Press}
}

@article{eickhoff2016efficient,
  title={Efficient Parallel Learning of Word2Vec},
  author={Eickhoff, Carsten},
  year={2016}
}

@article{elcompression,
  title={Compression Through Language Modeling},
  author={El Daher, Antoine and Connor, James},
  year="2006"
}

@article{goldberg2014word2vec,
  title={word2vec explained: Deriving mikolov et al.'s negative-sampling word-embedding method},
  author={Goldberg, Yoav and Levy, Omer},
  journal={arXiv preprint arXiv:1402.3722},
  year={2014}
}

@article{godel1931formal,
  title={{\"U}ber formal unentscheidbare S{\"a}tze der Principia Mathematica und verwandter Systeme I},
  author={G{\"o}del, Kurt},
  journal={Monatshefte f{\"u}r mathematik und physik},
  volume={38},
  number={1},
  pages={173--198},
  year={1931},
  publisher={Springer}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{gutmann2012noise,
  title={Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics},
  author={Gutmann, Michael U and Hyv{\"a}rinen, Aapo},
  journal={Journal of Machine Learning Research},
  volume={13},
  number={Feb},
  pages={307--361},
  year={2012}
}

@article{harris1954distributional,
  title={Distributional structure},
  author={Harris, Zellig S},
  journal={Word},
  volume={10},
  number={2-3},
  pages={146--162},
  year={1954},
  publisher={Taylor \& Francis}
}

@article{ji2016parallelizing,
  title={Parallelizing word2vec in shared and distributed memory},
  author={Ji, Shihao and Satish, Nadathur and Li, Sheng and Dubey, Pradeep},
  journal={arXiv preprint arXiv:1604.04661},
  year={2016}
}

@inproceedings{le2014distributed,
  title={Distributed Representations of Sentences and Documents},
  author={Le, Quoc V and Mikolov, Tomas},
  booktitle={ICML},
  volume={14},
  pages={1188--1196},
  year="2014"
}

@article{Levy2014neural,
abstract = {We analyze skip-gram with negative-sampling (SGNS), a word embedding method introduced by Mikolov et al., and show that it is implicitly factorizing a word-context matrix, whose cells are the pointwise mutual information (PMI) of the respective word and context pairs, shifted by a global constant. We find that another embedding method, NCE, is implicitly factorizing a similar matrix, where each cell is the (shifted) log conditional probability of a word given its context. We show that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks. When dense low-dimensional vectors are preferred, exact factorization with SVD can achieve solutions that are at least as good as SGNS's solutions for word simi-larity tasks. On analogy questions SGNS remains superior to SVD. We conjecture that this stems from the weighted nature of SGNS's factorization.},
archivePrefix = {arXiv},
arxivId = {1405.4053},
author = {Levy, Omer and Goldberg, Yoav},
doi = {10.1162/153244303322533223},
eprint = {1405.4053},
isbn = {9781634393973},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems (NIPS)},
mendeley-groups = {word embedding},
pages = {2177--2185},
pmid = {1710995},
title = {{Neural Word Embedding as Implicit Matrix Factorization}},
url = {http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization},
year = {2014}
}

@article{levy2015improving,
  title={Improving distributional similarity with lessons learned from word embeddings},
  author={Levy, Omer and Goldberg, Yoav and Dagan, Ido},
  journal={Transactions of the Association for Computational Linguistics},
  volume={3},
  pages={211--225},
  year={2015}
}

@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  pages={3111--3119},
  year={2013}
}

@inproceedings{ordentlich2016network,
  title={Network-Efficient Distributed Word2vec Training System for Large Vocabularies},
  author={Ordentlich, Erik and Yang, Lee and Feng, Andy and Cnudde, Peter and Grbovic, Mihajlo and Djuric, Nemanja and Radosavljevic, Vladan and Owens, Gavin},
  booktitle={Proceedings of the 25th ACM International on Conference on Information and Knowledge Management},
  pages={1139--1148},
  year={2016},
  organization={ACM}
}

@article{Pennington2014glove,
abstract = {Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arith- metic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global log- bilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word co- occurrence matrix, rather than on the en- tire sparse matrix or on individual context windows in a large corpus. On a recent word analogy task our model obtains 75{\%} accuracy, an improvement of 11{\%} over Mikolov et al. (2013). It also outperforms related word vector models on similarity tasks and named entity recognition.},
archivePrefix = {arXiv},
arxivId = {1504.06654},
author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
doi = {10.3115/v1/D14-1162},
eprint = {1504.06654},
isbn = {9781937284961},
issn = {10495258},
journal = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing},
mendeley-groups = {other distributional representation},
pages = {1532--1543},
pmid = {1710995},
title = {{GloVe: Global Vectors for Word Representation}},
year = {2014}
}

@inproceedings{recht2011hogwild,
  title={Hogwild: A lock-free approach to parallelizing stochastic gradient descent},
  author={Recht, Benjamin and Re, Christopher and Wright, Stephen and Niu, Feng},
  booktitle={Advances in Neural Information Processing Systems},
  pages={693--701},
  year={2011}
}

@inproceedings{schutze2008introduction,
  title={Introduction to Information Retrieval},
  author={Sch{\"u}tze, Hinrich},
  booktitle={Proceedings of the international communication of association for computing machinery conference},
  year="2008",
  pages="22--27"
}

@inproceedings{turian2010word,
  title={Word representations: a simple and general method for semi-supervised learning},
  author={Turian, Joseph and Ratinov, Lev and Bengio, Yoshua},
  booktitle={Proceedings of the 48th annual meeting of the association for computational linguistics},
  pages={384--394},
  year={2010},
  organization={Association for Computational Linguistics}
}

@article{weston2011wsabie,
  title={Wsabie: Scaling up to large vocabulary image annotation},
  author={Weston, Jason and Bengio, Samy and Usunier, Nicolas},
  year="2011"
}

@article{williams1986learning,
  title={Learning representations by back-propagating errors},
  author={Williams, DRGHR and Hinton, GE},
  journal={Nature},
  volume={323},
  pages={533--536},
  year="1986"
}
