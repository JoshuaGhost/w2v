18/01/28 14:40:12 INFO Configuration.deprecation: mapred.task.timeout is deprecated. Instead, use mapreduce.task.timeout
18/01/28 14:40:12 INFO Configuration.deprecation: map.output.key.field.separator is deprecated. Instead, use mapreduce.map.output.key.field.separator
18/01/28 14:40:12 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
18/01/28 14:40:12 WARN ipc.Client: Failed to connect to server: master.ib/10.12.0.1:8032: retries get failed due to exceeded maximum allowed retries number: 0
java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:648)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:744)
	at org.apache.hadoop.ipc.Client$Connection.access$3000(Client.java:396)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1557)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1441)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy13.getNewApplication(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getNewApplication(ApplicationClientProtocolPBClientImpl.java:217)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:260)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
	at com.sun.proxy.$Proxy14.getNewApplication(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getNewApplication(YarnClientImpl.java:206)
	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.createApplication(YarnClientImpl.java:214)
	at org.apache.hadoop.mapred.ResourceMgrDelegate.getNewJobID(ResourceMgrDelegate.java:187)
	at org.apache.hadoop.mapred.YARNRunner.getNewJobID(YARNRunner.java:262)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:157)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1307)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1304)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1304)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:578)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:573)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:573)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:564)
	at org.apache.hadoop.streaming.StreamJob.submitAndMonitorJob(StreamJob.java:1017)
	at org.apache.hadoop.streaming.StreamJob.run(StreamJob.java:135)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
18/01/28 14:40:13 INFO client.ConfiguredRMFailoverProxyProvider: Failing over to rm1330
18/01/28 14:40:14 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library
18/01/28 14:40:14 INFO lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev cd638c1072adb77be8289b18f7efcd140a2d515c]
18/01/28 14:40:14 INFO mapred.FileInputFormat: Total input paths to process : 1
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.22:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.18:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.34:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.6:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.35:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.19:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.3:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.28:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.16:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.4:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.7:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.29:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.11:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.15:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.33:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.25:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.23:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.13:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.26:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.2:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.14:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.31:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.10:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.5:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.12:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.9:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.30:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.27:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.1:50010
18/01/28 14:40:14 INFO net.NetworkTopology: Adding a new node: /default/10.12.1.32:50010
18/01/28 14:40:15 INFO mapreduce.JobSubmitter: number of splits:100
18/01/28 14:40:15 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1516212768025_0339
18/01/28 14:40:15 INFO impl.YarnClientImpl: Submitted application application_1516212768025_0339
18/01/28 14:40:15 INFO mapreduce.Job: The url to track the job: http://master02.ib:8088/proxy/application_1516212768025_0339/
18/01/28 14:40:15 INFO mapreduce.Job: Running job: job_1516212768025_0339
18/01/28 14:40:34 INFO mapreduce.Job: Job job_1516212768025_0339 running in uber mode : false
18/01/28 14:40:34 INFO mapreduce.Job:  map 0% reduce 0%
18/01/28 14:40:45 INFO mapreduce.Job:  map 3% reduce 0%
18/01/28 14:40:52 INFO mapreduce.Job:  map 9% reduce 0%
18/01/28 14:40:55 INFO mapreduce.Job:  map 12% reduce 0%
18/01/28 14:40:56 INFO mapreduce.Job:  map 15% reduce 0%
18/01/28 14:41:01 INFO mapreduce.Job:  map 18% reduce 0%
18/01/28 14:41:02 INFO mapreduce.Job:  map 25% reduce 0%
18/01/28 14:41:03 INFO mapreduce.Job:  map 34% reduce 0%
18/01/28 14:41:04 INFO mapreduce.Job:  map 50% reduce 0%
18/01/28 14:41:05 INFO mapreduce.Job:  map 57% reduce 0%
18/01/28 14:41:06 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 14:41:07 INFO mapreduce.Job:  map 74% reduce 0%
18/01/28 14:41:08 INFO mapreduce.Job:  map 80% reduce 0%
18/01/28 14:41:09 INFO mapreduce.Job:  map 85% reduce 0%
18/01/28 14:41:10 INFO mapreduce.Job:  map 87% reduce 0%
18/01/28 14:41:11 INFO mapreduce.Job:  map 89% reduce 0%
18/01/28 14:41:14 INFO mapreduce.Job:  map 90% reduce 0%
18/01/28 14:48:06 INFO mapreduce.Job:  map 91% reduce 0%
18/01/28 14:48:28 INFO mapreduce.Job:  map 92% reduce 0%
18/01/28 14:48:38 INFO mapreduce.Job:  map 94% reduce 0%
18/01/28 14:48:53 INFO mapreduce.Job:  map 95% reduce 0%
18/01/28 14:48:59 INFO mapreduce.Job:  map 96% reduce 0%
18/01/28 14:49:32 INFO mapreduce.Job:  map 97% reduce 0%
18/01/28 14:49:33 INFO mapreduce.Job:  map 99% reduce 0%
18/01/28 14:54:09 INFO mapreduce.Job:  map 100% reduce 0%
18/01/28 14:54:10 INFO mapreduce.Job:  map 100% reduce 3%
18/01/28 14:54:11 INFO mapreduce.Job:  map 100% reduce 70%
18/01/28 14:54:12 INFO mapreduce.Job:  map 100% reduce 100%
18/01/28 14:54:14 INFO mapreduce.Job: Job job_1516212768025_0339 completed successfully
18/01/28 14:54:14 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=11355623938
		FILE: Number of bytes written=16961284752
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=17884443418
		HDFS: Number of bytes written=1822226625
		HDFS: Number of read operations=600
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=200
	Job Counters 
		Launched map tasks=100
		Launched reduce tasks=100
		Data-local map tasks=85
		Rack-local map tasks=15
		Total time spent by all maps in occupied slots (ms)=37909585
		Total time spent by all reduces in occupied slots (ms)=157539540
		Total time spent by all map tasks (ms)=7581917
		Total time spent by all reduce tasks (ms)=31507908
		Total vcore-milliseconds taken by all map tasks=7581917
		Total vcore-milliseconds taken by all reduce tasks=31507908
		Total megabyte-milliseconds taken by all map tasks=77638830080
		Total megabyte-milliseconds taken by all reduce tasks=322640977920
	Map-Reduce Framework
		Map input records=10
		Map output records=6925000
		Map output bytes=7523593791
		Map output materialized bytes=5649737389
		Input split bytes=9300
		Combine input records=0
		Combine output records=0
		Reduce input groups=6925000
		Reduce shuffle bytes=5649737389
		Reduce input records=6925000
		Reduce output records=172488
		Spilled Records=20775000
		Shuffled Maps =10000
		Failed Shuffles=0
		Merged Map outputs=10000
		GC time elapsed (ms)=23438
		CPU time spent (ms)=1401640
		Physical memory (bytes) snapshot=167323099136
		Virtual memory (bytes) snapshot=1823879397376
		Total committed heap usage (bytes)=307192397824
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=17884434118
	File Output Format Counters 
		Bytes Written=1822226625
18/01/28 14:54:14 INFO streaming.StreamJob: Output directory: train_10_smaller_origin
