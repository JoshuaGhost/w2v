18/01/28 13:01:43 INFO Configuration.deprecation: map.output.key.field.separator is deprecated. Instead, use mapreduce.map.output.key.field.separator
18/01/28 13:01:43 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
18/01/28 13:01:44 WARN ipc.Client: Failed to connect to server: master.ib/10.12.0.1:8032: retries get failed due to exceeded maximum allowed retries number: 0
java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:648)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:744)
	at org.apache.hadoop.ipc.Client$Connection.access$3000(Client.java:396)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1557)
	at org.apache.hadoop.ipc.Client.call(Client.java:1480)
	at org.apache.hadoop.ipc.Client.call(Client.java:1441)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy13.getNewApplication(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getNewApplication(ApplicationClientProtocolPBClientImpl.java:217)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:260)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:104)
	at com.sun.proxy.$Proxy14.getNewApplication(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getNewApplication(YarnClientImpl.java:206)
	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.createApplication(YarnClientImpl.java:214)
	at org.apache.hadoop.mapred.ResourceMgrDelegate.getNewJobID(ResourceMgrDelegate.java:187)
	at org.apache.hadoop.mapred.YARNRunner.getNewJobID(YARNRunner.java:262)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:157)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1307)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1304)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1304)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:578)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:573)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:573)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:564)
	at org.apache.hadoop.streaming.StreamJob.submitAndMonitorJob(StreamJob.java:1017)
	at org.apache.hadoop.streaming.StreamJob.run(StreamJob.java:135)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
18/01/28 13:01:44 INFO client.ConfiguredRMFailoverProxyProvider: Failing over to rm1330
18/01/28 13:01:46 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library
18/01/28 13:01:46 INFO lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev cd638c1072adb77be8289b18f7efcd140a2d515c]
18/01/28 13:01:46 INFO mapred.FileInputFormat: Total input paths to process : 1
18/01/28 13:01:46 INFO mapreduce.JobSubmitter: number of splits:24
18/01/28 13:01:46 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1516212768025_0333
18/01/28 13:01:47 INFO impl.YarnClientImpl: Submitted application application_1516212768025_0333
18/01/28 13:01:47 INFO mapreduce.Job: The url to track the job: http://master02.ib:8088/proxy/application_1516212768025_0333/
18/01/28 13:01:47 INFO mapreduce.Job: Running job: job_1516212768025_0333
18/01/28 13:02:01 INFO mapreduce.Job: Job job_1516212768025_0333 running in uber mode : false
18/01/28 13:02:01 INFO mapreduce.Job:  map 0% reduce 0%
18/01/28 13:02:17 INFO mapreduce.Job:  map 3% reduce 0%
18/01/28 13:02:26 INFO mapreduce.Job:  map 6% reduce 0%
18/01/28 13:02:27 INFO mapreduce.Job:  map 14% reduce 0%
18/01/28 13:02:28 INFO mapreduce.Job:  map 22% reduce 0%
18/01/28 13:02:33 INFO mapreduce.Job:  map 25% reduce 0%
18/01/28 13:02:38 INFO mapreduce.Job:  map 33% reduce 0%
18/01/28 13:02:39 INFO mapreduce.Job:  map 42% reduce 0%
18/01/28 13:02:40 INFO mapreduce.Job:  map 44% reduce 0%
18/01/28 13:02:41 INFO mapreduce.Job:  map 47% reduce 0%
18/01/28 13:02:42 INFO mapreduce.Job:  map 50% reduce 0%
18/01/28 13:02:43 INFO mapreduce.Job:  map 56% reduce 0%
18/01/28 13:02:50 INFO mapreduce.Job:  map 58% reduce 0%
18/01/28 13:03:00 INFO mapreduce.Job:  map 61% reduce 0%
18/01/28 13:03:02 INFO mapreduce.Job:  map 64% reduce 0%
18/01/28 13:03:08 INFO mapreduce.Job:  map 67% reduce 0%
18/01/28 13:03:20 INFO mapreduce.Job:  map 68% reduce 0%
18/01/28 13:03:23 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000013_0, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:03:24 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:03:24 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000015_0, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:03:25 INFO mapreduce.Job:  map 63% reduce 0%
18/01/28 13:03:40 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:03:41 INFO mapreduce.Job:  map 68% reduce 0%
18/01/28 13:08:38 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000001_0, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:08:39 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:08:42 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000002_0, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:08:43 INFO mapreduce.Job:  map 63% reduce 0%
18/01/28 13:08:56 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:09:00 INFO mapreduce.Job:  map 68% reduce 0%
18/01/28 13:10:53 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000000_0, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:10:54 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:11:18 INFO mapreduce.Job:  map 68% reduce 0%
18/01/28 13:11:23 INFO mapreduce.Job:  map 69% reduce 0%
18/01/28 13:11:26 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000003_0, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:11:27 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:11:45 INFO mapreduce.Job:  map 68% reduce 0%
18/01/28 13:12:30 INFO mapreduce.Job:  map 54% reduce 0%
18/01/28 13:12:30 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000006_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000006_0 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

18/01/28 13:12:30 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000012_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000012_0 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

18/01/28 13:12:30 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000016_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000016_0 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

18/01/28 13:12:30 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000009_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000009_0 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

18/01/28 13:12:31 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000014_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000014_0 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

18/01/28 13:12:41 INFO mapreduce.Job:  map 55% reduce 0%
18/01/28 13:12:43 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000003_1, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:12:44 INFO mapreduce.Job:  map 51% reduce 0%
18/01/28 13:12:47 INFO mapreduce.Job:  map 63% reduce 0%
18/01/28 13:12:48 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:13:00 INFO mapreduce.Job:  map 68% reduce 0%
18/01/28 13:13:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000005_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000005_0 Timed out after 600 secs
18/01/28 13:13:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000021_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000021_0 Timed out after 600 secs
18/01/28 13:13:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000022_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000022_0 Timed out after 600 secs
18/01/28 13:13:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000020_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000020_0 Timed out after 600 secs
18/01/28 13:13:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000008_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000008_0 Timed out after 600 secs
18/01/28 13:13:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000007_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000007_0 Timed out after 600 secs
18/01/28 13:13:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000011_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000011_0 Timed out after 600 secs
18/01/28 13:13:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000019_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000019_0 Timed out after 600 secs
18/01/28 13:13:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000018_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000018_0 Timed out after 600 secs
18/01/28 13:13:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000010_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000010_0 Timed out after 600 secs
18/01/28 13:13:01 INFO mapreduce.Job:  map 38% reduce 0%
18/01/28 13:13:01 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000004_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000004_0 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

18/01/28 13:13:17 INFO mapreduce.Job:  map 60% reduce 0%
18/01/28 13:13:18 INFO mapreduce.Job:  map 63% reduce 0%
18/01/28 13:13:20 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000012_1, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:13:21 INFO mapreduce.Job:  map 60% reduce 0%
18/01/28 13:13:30 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000017_0, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000017_0 Timed out after 600 secs
18/01/28 13:13:31 INFO mapreduce.Job:  map 57% reduce 0%
18/01/28 13:13:37 INFO mapreduce.Job:  map 58% reduce 0%
18/01/28 13:13:38 INFO mapreduce.Job:  map 60% reduce 0%
18/01/28 13:13:39 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000003_2, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:13:40 INFO mapreduce.Job:  map 57% reduce 0%
18/01/28 13:13:41 INFO mapreduce.Job:  map 60% reduce 0%
18/01/28 13:13:46 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000008_1, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:13:49 INFO mapreduce.Job:  map 63% reduce 0%
18/01/28 13:13:52 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000007_1, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:13:53 INFO mapreduce.Job:  map 60% reduce 0%
18/01/28 13:13:56 INFO mapreduce.Job:  map 63% reduce 0%
18/01/28 13:14:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000015_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000015_1 Timed out after 600 secs
18/01/28 13:14:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000013_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000013_1 Timed out after 600 secs
18/01/28 13:14:01 INFO mapreduce.Job:  map 57% reduce 0%
18/01/28 13:14:05 INFO mapreduce.Job:  map 60% reduce 0%
18/01/28 13:14:07 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000020_1, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:14:08 INFO mapreduce.Job:  map 57% reduce 0%
18/01/28 13:14:10 INFO mapreduce.Job:  map 60% reduce 0%
18/01/28 13:14:17 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:14:20 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000012_2, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:14:21 INFO mapreduce.Job:  map 63% reduce 0%
18/01/28 13:14:25 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:14:43 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000013_2, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:14:44 INFO mapreduce.Job:  map 63% reduce 0%
18/01/28 13:14:46 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:14:47 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000007_2, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:14:48 INFO mapreduce.Job:  map 63% reduce 0%
18/01/28 13:15:00 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:15:04 INFO mapreduce.Job:  map 68% reduce 0%
18/01/28 13:15:07 INFO mapreduce.Job:  map 69% reduce 0%
18/01/28 13:15:07 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000020_2, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:15:08 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:15:24 INFO mapreduce.Job:  map 68% reduce 0%
18/01/28 13:19:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000002_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000002_1 Timed out after 600 secs
18/01/28 13:19:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000001_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000001_1 Timed out after 600 secs
18/01/28 13:19:01 INFO mapreduce.Job:  map 63% reduce 0%
18/01/28 13:19:17 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:19:18 INFO mapreduce.Job:  map 68% reduce 0%
18/01/28 13:21:30 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000000_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000000_1 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

18/01/28 13:21:31 INFO mapreduce.Job:  map 65% reduce 0%
18/01/28 13:21:46 INFO mapreduce.Job:  map 68% reduce 0%
18/01/28 13:23:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000006_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000006_1 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

18/01/28 13:23:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000014_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000014_1 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

18/01/28 13:23:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000016_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000016_1 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

18/01/28 13:23:00 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000009_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000009_1 Timed out after 600 secs
Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143
Container exited with a non-zero exit code 143

18/01/28 13:23:01 INFO mapreduce.Job:  map 57% reduce 0%
18/01/28 13:23:16 INFO mapreduce.Job:  map 63% reduce 0%
18/01/28 13:23:17 INFO mapreduce.Job:  map 68% reduce 0%
18/01/28 13:23:29 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000010_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000010_1 Timed out after 600 secs
18/01/28 13:23:29 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000018_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000018_1 Timed out after 600 secs
18/01/28 13:23:29 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000019_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000019_1 Timed out after 600 secs
18/01/28 13:23:29 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000011_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000011_1 Timed out after 600 secs
18/01/28 13:23:29 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000004_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000004_1 Timed out after 600 secs
18/01/28 13:23:29 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000005_1, Status : FAILED
AttemptID:attempt_1516212768025_0333_m_000005_1 Timed out after 600 secs
18/01/28 13:23:30 INFO mapreduce.Job:  map 51% reduce 0%
18/01/28 13:23:46 INFO mapreduce.Job:  map 54% reduce 0%
18/01/28 13:23:47 INFO mapreduce.Job:  map 60% reduce 0%
18/01/28 13:23:49 INFO mapreduce.Job: Task Id : attempt_1516212768025_0333_m_000014_2, Status : FAILED
Error: java.lang.NegativeArraySizeException
	at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:436)
	at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:341)
	at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:323)
	at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:567)
	at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:209)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1943)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1514)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:466)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1917)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)

18/01/28 13:23:50 INFO mapreduce.Job:  map 57% reduce 0%
18/01/28 13:24:00 INFO mapreduce.Job:  map 100% reduce 100%
18/01/28 13:24:01 INFO mapreduce.Job: Job job_1516212768025_0333 failed with state FAILED due to: Task failed task_1516212768025_0333_m_000003
Job failed as tasks failed. failedMaps:1 failedReduces:0

18/01/28 13:24:02 INFO mapreduce.Job: Counters: 37
	File System Counters
		FILE: Number of bytes read=977002925
		FILE: Number of bytes written=1952477438
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=87593959
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=3
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
	Job Counters 
		Failed map tasks=53
		Killed map tasks=22
		Killed reduce tasks=10
		Launched map tasks=73
		Other local map tasks=49
		Data-local map tasks=19
		Rack-local map tasks=5
		Total time spent by all maps in occupied slots (ms)=151575210
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=30315042
		Total vcore-milliseconds taken by all map tasks=30315042
		Total megabyte-milliseconds taken by all map tasks=310426030080
	Map-Reduce Framework
		Map input records=17177
		Map output records=343541
		Map output bytes=1767576768
		Map output materialized bytes=976156604
		Input split bytes=102
		Combine input records=0
		Spilled Records=687082
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=503
		CPU time spent (ms)=46810
		Physical memory (bytes) snapshot=6072782848
		Virtual memory (bytes) snapshot=10884751360
		Total committed heap usage (bytes)=6783238144
	File Input Format Counters 
		Bytes Read=87593857
18/01/28 13:24:02 ERROR streaming.StreamJob: Job not successful!
Streaming Command Failed!
